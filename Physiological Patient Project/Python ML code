import pandas as pd

df = pd.read_csv('./eicu_cohort.csv')
df.head()
df.info()

# rename some column names
df=df.rename( {"unabridgedhosplos":"length of stay",
          "meanbp": "mean blood pressure",
          "wbc": "white cell count"} )

#### Look for missing values
          

# convert boolean columns to a categorical type
df['actualhospitalmortality']  = pd.Categorical(df['actualhospitalmortality'], categories=['Alive','Expired'])    # 0 is Alive, 1 is Expired

# convert gender column to a categorical type
df['gender'] = pd.Categorical(df['gender'])
df['gender'] = df['gender'].cat.codes

# add the encoded value to a new column
df['actualhospitalmortality_enc'] = df['actualhospitalmortality'].cat.codes
df[['actualhospitalmortality_enc','actualhospitalmortality']].head()

############# Prepping Test and Data Sets
from sklearn.model_selection import train_test_split

x = df.drop('actualhospitalmortality', axis=1)
y = df['actualhospitalmortality']
x_train, x_test, y_train, y_test = train_test_split(x, y, train_size = 0.7, random_state = 42)

#############Checking for missing data
# We will use the training median to replace missing values in both the test and training data, this will avoid data leaking between the two sets

# impute missing values from the training set
x_train = x_train.fillna(x_train.median())
x_test = x_test.fillna(x_train.median())


############# Normalization
# there are several pre-built normilization programs\packages
#Min-Max Scaler (General normalization): Subtract mean, divide by standard deviation. from sklearn package which scales each feature between zero and one

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()                             # Set up scaler model

# Alternative is zero mean, unit variance
# from sklearn.preprocessing import StandardScaler

scaler.fit(x_train)                                 # apply\fit the scaler on the training dataset
x_train = scaler.transform(x_train)                 # scale the training set

x_test = scaler.transform(x_test)                   # scale the test set

############# Linear Regression for Apache Score
# import the regression model
import numpy as np
from matplotlib import pyplot as plt
from sklearn.linear_model import LinearRegression
reg = LinearRegression()                                      # create model

# use a single feature (apache score)
# note: remove the reshape if fitting to >1 input variable
X = df['col_name'].values.reshape(-1, 1)
y = df['col_name'].values


reg = reg.fit(X, y)                                           # fit the model to our data

# get the y values
buffer = 0.2*max(X)
X_fit = np.linspace(min(X) - buffer, max(X) + buffer, num=50)
y_fit = reg.predict(X_fit)

# plot
plt.scatter(X, y,  color='black', marker = 'x')               # the red line is calculated to minimize the error between the line and the points
plt.plot(X_fit, y_fit, color='red', linewidth=2)
plt.show()

############### Linear Regression
# define features and outcome
features = ['apachescore']
outcome = ['actualhospitalmortality_enc']

# partition data into training and test sets
X = cohort[features]
y = cohort[outcome]
x_train, x_test, y_train, y_test = train_test_split(X, y, train_size = 0.7, random_state = 42)

# restructure data for input into model
# note: remove the reshape if fitting to >1 input variable
x_train = x_train.values.reshape(-1, 1)
y_train = y_train.values.ravel()
x_test = x_test.values.reshape(-1, 1)
y_test = y_test.values.ravel()

# train model
reg = LogisticRegression(random_state=0)
reg.fit(x_train, y_train)

# generate predictions
y_hat_train = reg.predict(x_train)
y_hat_test = reg.predict(x_test)
y_hat_test_proba = reg.predict_proba(x_test)      # each prediction has a probability. For example, how probable that prediction is.

################ Confusion matrix
from sklearn import metrics
confusion = metrics.confusion_matrix(y_test, y_hat_test)

class_names=cohort['actualhospitalmortality'].cat.categories
disp = metrics.ConfusionMatrixDisplay.from_estimator(
    reg, x_test, y_test, display_labels=class_names,
    cmap=plt.cm.Blues)

plt.show()

## Model Accuracy with Confusion Matrix >> .82
acc = metrics.accuracy_score(y_test, y_hat_test)
print(f"Accuracy (model) = {acc:.2f}")


########### Accuracy
#  accuracy on training set
acc_train = np.mean(y_hat_train == y_train)
print(f'Accuracy on training set: {acc_train:.2f}')

#  accuracy on test set
acc_test = np.mean(y_hat_test == y_test)
print(f'Accuracy on test set: {acc_test:.2f}')
